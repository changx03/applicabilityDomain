{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from adad.torch_utils import NNClassifier, get_correct_examples\n",
    "from adad.utils import open_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lukec/workspace/applicabilityDomain\n"
     ]
    }
   ],
   "source": [
    "PATH_ROOT = Path(os.getcwd()).absolute().parent.parent\n",
    "print(PATH_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\n",
    "    \"abalone\",\n",
    "    \"australian\",\n",
    "    \"banknote\",\n",
    "    \"breastcancer\",\n",
    "    \"htru2\",\n",
    "    \"phoneme\",\n",
    "    \"ringnorm\",\n",
    "    \"texture\",\n",
    "]\n",
    "ATTACKS = [\n",
    "    'fgsm',\n",
    "    'apgd',\n",
    "    'cw2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_metrics(index, dataname):\n",
    "    path_train = os.path.join(PATH_ROOT, 'results', 'numeric', f'run_{index}', 'train', f'{dataname}_train.csv')\n",
    "    path_validation = os.path.join(PATH_ROOT, 'results', 'numeric', f'run_{index}', 'validation', f'{dataname}_val.csv')\n",
    "    path_test = os.path.join(PATH_ROOT, 'results', 'numeric', f'run_{index}', 'test', f'{dataname}_test.csv')\n",
    "    path_model = os.path.join(PATH_ROOT, 'results', 'numeric', f'run_{index}', 'clf', dataname)\n",
    "\n",
    "    X_train, y_train, _ = open_csv(path_train)\n",
    "    X_val, y_val, _ = open_csv(path_validation)\n",
    "    X_test, y_test, _ = open_csv(path_test)\n",
    "\n",
    "    clf = NNClassifier()\n",
    "    clf.load(path_model)\n",
    "\n",
    "    _, y_train_fil = get_correct_examples(clf.clf, X_train, y_train, clf.device)\n",
    "    _, y_val_fil = get_correct_examples(clf.clf, X_val, y_val, clf.device)\n",
    "    _, y_test_fil = get_correct_examples(clf.clf, X_test, y_test, clf.device)\n",
    "\n",
    "    row = pd.Series({\n",
    "        'Data': dataname,\n",
    "        'Features': X_train.shape[1],\n",
    "        'Classes': int(len(np.unique(y_train))),\n",
    "        'Train': int(y_train.shape[0]),\n",
    "        'Val': int(y_val.shape[0]),\n",
    "        'Test': int(y_test.shape[0]),\n",
    "        'Train-Acc': len(y_train_fil) / y_train.shape[0] * 100.,\n",
    "        'Val-Acc': len(y_val_fil) / y_val.shape[0] * 100.,\n",
    "        'Test-Acc': len(y_test_fil) / y_test.shape[0] * 100.,\n",
    "        })\n",
    "    return row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repeated = []\n",
    "for i in range(5):\n",
    "    _df = pd.DataFrame({\n",
    "        'Data': [],\n",
    "        'Features': [],\n",
    "        'Classes': [],\n",
    "        'Train':[],\n",
    "        'Val': [],\n",
    "        'Test': [],\n",
    "        'Train-Acc':[],\n",
    "        'Val-Acc': [],\n",
    "        'Test-Acc': [],\n",
    "    })\n",
    "    col_int_names = ['Features', 'Classes', 'Train', 'Val', 'Test']\n",
    "    _df[col_int_names] = _df[col_int_names].astype(int)\n",
    "    df_repeated.append(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, run in enumerate(range(1, 6)):\n",
    "    for dataset in DATASETS:\n",
    "        row = get_clf_metrics(run, dataset)\n",
    "        df_repeated[i] = df_repeated[i].append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = pd.concat(df_repeated).groupby(by='Data').mean()\n",
    "df_mean = df_mean.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "        Data &  Features &  Classes &   Train &     Val &    Test &  Train-Acc &  Val-Acc &  Test-Acc \\\\\n",
      "\\midrule\n",
      "     abalone &      7.00 &     2.00 & 2504.00 &  835.00 &  835.00 &      80.72 &    78.78 &     79.38 \\\\\n",
      "  australian &     14.00 &     2.00 &  414.00 &  138.00 &  138.00 &      96.52 &    84.35 &     82.03 \\\\\n",
      "    banknote &      4.00 &     2.00 &  822.00 &  275.00 &  275.00 &     100.00 &   100.00 &    100.00 \\\\\n",
      "breastcancer &     30.00 &     2.00 &  341.00 &  114.00 &  114.00 &     100.00 &    95.61 &     96.14 \\\\\n",
      "       htru2 &      8.00 &     2.00 & 2457.00 &  820.00 &  820.00 &      95.28 &    95.15 &     95.02 \\\\\n",
      "     phoneme &      5.00 &     2.00 & 2379.00 &  793.00 &  793.00 &      85.66 &    83.05 &     83.88 \\\\\n",
      "    ringnorm &     20.00 &     2.00 & 4439.00 & 1480.00 & 1480.00 &      99.86 &    96.77 &     96.70 \\\\\n",
      "     texture &     40.00 &    11.00 & 3300.00 & 1100.00 & 1100.00 &      99.38 &    99.09 &     99.18 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_mean.to_latex(index=False, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advx_metrics(run_num, dataname, attack):\n",
    "    \"\"\"Get performance metrics for adversarial attack.\"\"\"\n",
    "    path_model = os.path.join(PATH_ROOT, 'results', 'numeric', f'run_{run}', 'clf', dataname)\n",
    "    clf = NNClassifier()\n",
    "    clf.load(path_model)\n",
    "\n",
    "    path_advx_re = os.path.join(PATH_ROOT, 'results', 'numeric', f'run_{run_num}', attack, f'{dataname}_{attack}_*.csv')\n",
    "    paths_advx = sorted(glob(path_advx_re))\n",
    "    # print(paths_advx)\n",
    "\n",
    "    _df = pd.DataFrame()\n",
    "    for path_advx in paths_advx:\n",
    "        # Get hyperparameter for adversarial attack; FGSM is epsilon, CW2 is C.\n",
    "        param = float(Path(path_advx).stem.split('_')[-1])\n",
    "        # print(param)\n",
    "\n",
    "        X_advx, y_true, _ = open_csv(path_advx)\n",
    "        acc_advx = clf.score(X_advx, y_true)\n",
    "        row = pd.Series({\n",
    "            'Data': dataname,\n",
    "            'Attack': attack,\n",
    "            'Param': param,\n",
    "            'Accuracy': acc_advx,\n",
    "        })\n",
    "        _df = _df.append(row, ignore_index=True)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advx_repeated = []\n",
    "for i in range(5):\n",
    "    _df = pd.DataFrame({\n",
    "        'Data': [],\n",
    "        'Attack': [],\n",
    "        'Param': [],\n",
    "        'Accuracy': [],\n",
    "    })\n",
    "    df_advx_repeated.append(_df)\n",
    "\n",
    "for i, run in enumerate(range(1, 6)):\n",
    "    for dataname in DATASETS:\n",
    "        for att in ATTACKS:\n",
    "            _df = get_advx_metrics(run, dataname, att)\n",
    "            df_advx_repeated[i] = df_advx_repeated[i].append(_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Data Attack  Param   Accuracy\n",
      "0    abalone   apgd    0.1  63.841583\n",
      "1    abalone   apgd    0.3  22.453503\n",
      "2    abalone   apgd    0.6   6.119547\n",
      "3    abalone   apgd    1.0   0.607465\n",
      "4    abalone   apgd    1.5   0.000000\n",
      "..       ...    ...    ...        ...\n",
      "99   texture   fgsm    0.1  73.742863\n",
      "100  texture   fgsm    0.3  17.452203\n",
      "101  texture   fgsm    0.6   8.161906\n",
      "102  texture   fgsm    1.0   4.970743\n",
      "103  texture   fgsm    1.5   3.741727\n",
      "\n",
      "[104 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_advx_mean = pd.concat(df_advx_repeated).groupby(by=['Data', 'Attack', 'Param']).mean()\n",
    "df_advx_mean = df_advx_mean.reset_index()\n",
    "df_advx_mean['Accuracy'] = df_advx_mean['Accuracy'] * 100.\n",
    "print(df_advx_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advx_mean_other = df_advx_mean[df_advx_mean['Attack'] != 'cw2'].pivot(index=['Data', 'Attack'], columns='Param', values='Accuracy')\n",
    "df_advx_mean_other.to_csv(os.path.join(PATH_ROOT, 'plot_results', 'numeric', 'advx_metrics_other.csv'))\n",
    "\n",
    "df_advx_mean_cw2 = df_advx_mean[df_advx_mean['Attack'] == 'cw2'].pivot(index=['Data', 'Attack'], columns='Param', values='Accuracy')\n",
    "df_advx_mean_cw2.to_csv(os.path.join(PATH_ROOT, 'plot_results', 'numeric', 'advx_metrics_cw2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
