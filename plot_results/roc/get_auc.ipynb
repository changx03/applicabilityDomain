{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay, auc\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ROOT = Path(os.getcwd()).absolute().parent.parent\n",
    "print(PATH_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS = ['KNeighborsClassifier', 'NNClassifier', 'RandomForestClassifier', 'SVC']\n",
    "CLF_alias = ['KNN', 'NN', 'RF', 'SVM']\n",
    "AD = ['DAIndexDelta', \n",
    "      'DAIndexGamma', \n",
    "      'DAIndexKappa', \n",
    "      'PCABoundingBox', \n",
    "      'ProbabilityClassifier', \n",
    "      'Magnet',\n",
    "      'SklearnFeatureSqueezing', \n",
    "      'SklearnRegionBasedClassifier',\n",
    "]\n",
    "AD_alias = ['DM-δ',\n",
    "            'DM-γ',\n",
    "            'DM-κ',\n",
    "            'BB',\n",
    "            'Prob.',\n",
    "            'Magnet',\n",
    "            'FS',\n",
    "            'RC'\n",
    "]\n",
    "AL = ['Magnet', 'FS', 'RC']\n",
    "DATASETS = ['Ames', 'BBBP', 'Cancer', 'CYP1A2', 'hERG', 'HIV', 'Liver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(model, ad, dataset, suffix='roc'):\n",
    "    \"\"\"Return a full path of the ROC results;\"\"\"\n",
    "    path_file = os.path.join(PATH_ROOT, 'results', f'{model}_{ad}', f'{dataset}_{suffix}.csv')\n",
    "    return path_file\n",
    "\n",
    "# Test function\n",
    "df_test = pd.read_csv(get_data_path(CLASSIFIERS[0], AD[0], DATASETS[0]))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_tpr(clf, ad, dataset):\n",
    "    \"\"\"Get TPR on 5-fold CV on 1 dataset with 1 classifier and 1 AD method;\"\"\"\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    df = pd.read_csv(get_data_path(clf, ad, dataset))\n",
    "    tpr = []\n",
    "    # Results are saved as 5-fold CV, starts from 1 to 5;\n",
    "    for i in range(1, 6):\n",
    "        fold_fpr = df[f'cv{i}_fpr'].dropna().to_numpy()\n",
    "        fold_tpr = df[f'cv{i}_tpr'].dropna().to_numpy()\n",
    "        interp_tpr = np.interp(mean_fpr, fold_fpr, fold_tpr)\n",
    "        interp_tpr[0] = 0.\n",
    "        tpr.append(interp_tpr)\n",
    "\n",
    "    mean_tpr = np.mean(tpr, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_tpr = pd.Series(mean_tpr)\n",
    "    return mean_tpr\n",
    "\n",
    "# Test function\n",
    "res_test = get_mean_tpr(CLASSIFIERS[0], AD[0], DATASETS[0])\n",
    "print(res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_roc(clf, dataset):\n",
    "    \"\"\"Get a DataFrame that contains all AD method on 1 dataset and 1 classifier;\"\"\" \n",
    "    _df = pd.DataFrame({ 'fpr': np.linspace(0, 1, 100) })\n",
    "\n",
    "    for ad, ad_lbl in zip(AD, AD_alias):\n",
    "        # print(i, ad, ad_lbl)\n",
    "        _tpr = get_mean_tpr(clf, ad, dataset)\n",
    "        _df = pd.concat((_df, pd.DataFrame({ ad_lbl: _tpr })), axis=1)\n",
    "    return _df\n",
    "\n",
    "# Test function\n",
    "df_test = get_df_roc(CLASSIFIERS[0], DATASETS[0])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc(clf, clf_alias, dataset):\n",
    "    df_auc = pd.DataFrame({\n",
    "    'Dataset': [],\n",
    "    'Classifier': [],\n",
    "    'Method': [],\n",
    "    'AUC': [],\n",
    "    })\n",
    "    df_roc = get_df_roc(clf, dataset)\n",
    "    for i, ad in enumerate(df_roc.columns[1:]):\n",
    "        auc_score = auc(df_roc['fpr'], df_roc[ad])\n",
    "        row = [\n",
    "            dataset,\n",
    "            clf_alias,\n",
    "            ad,\n",
    "            auc_score\n",
    "        ]\n",
    "        df_auc.loc[len(df_auc)] = row\n",
    "    # Largest one should be #1.\n",
    "    # Use 'min' for the tie, e.g, [1, 2, 2, 4]\n",
    "    df_auc['Rank'] = rankdata(-df_auc['AUC'], method='min')\n",
    "    return df_auc\n",
    "\n",
    "\n",
    "# Test function\n",
    "df_test = get_auc(CLASSIFIERS[0], CLF_alias[0], DATASETS[0])\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc = pd.DataFrame()\n",
    "for dataset in DATASETS:\n",
    "    for clf, alias in zip(CLASSIFIERS, CLF_alias):\n",
    "        _df = get_auc(clf, alias, dataset)\n",
    "        df_auc = pd.concat((df_auc, _df), ignore_index=True)\n",
    "\n",
    "path_output = os.path.join(PATH_ROOT, 'plot_results', 'roc', 'auc.csv')\n",
    "print('Save to:', path_output)\n",
    "df_auc.to_csv(path_output, index=False)\n",
    "\n",
    "df_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_auc_heatmap(df, classifier, output=None, fontsize=12, figsize=(5, 5), show_title=False):\n",
    "    \"\"\"Plot heatmap per classifier.\"\"\"\n",
    "    df_selected = df[df['Classifier'] == classifier]\n",
    "    heatmap_data = df_selected.pivot('Dataset', 'Method', 'AUC')\n",
    "    \n",
    "    plt.rc('font', size=fontsize)\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(heatmap_data, \n",
    "                xticklabels=AD_alias,\n",
    "                cmap='YlGn',\n",
    "                annot=True, \n",
    "                fmt='.2f', \n",
    "                cbar=False)\n",
    "    plt.xlabel('Method', fontsize=fontsize+1)\n",
    "    plt.ylabel('Dataset', fontsize=fontsize+1)\n",
    "    if show_title:\n",
    "        plt.title(f'{classifier} AUC', fontsize=fontsize+4)\n",
    "    plt.tight_layout()\n",
    "    if output:\n",
    "        plt.savefig(output, dpi=300)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Test function\n",
    "create_auc_heatmap(df_auc, 'NN', show_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in CLF_alias:\n",
    "    path_output = os.path.join(PATH_ROOT, 'plot_results', 'roc', f'{clf}_auc_heatmap.pdf')\n",
    "    print('Save to:', path_output)\n",
    "    create_auc_heatmap(df_auc, clf, output=path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('adad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32470937e9edf2b7d9af0ed876fa250b771cc7b5d28c833a7c021d6de2615914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
